# Sanity Check Protocol

**Purpose**: Verify actual completion vs claimed completion after each track
**Invoke**: After completing any track, sprint deliverable, or major claim
**Created**: 2025-11-04 (Session 9.0 - AI-assistant challenge mitigation)

---

## Quick Checklist

Run through these 6 checks before claiming "complete":

### ‚òê 1. Build Verification
```bash
cd lean && lake build
```
- **Pass**: 0 errors (warnings OK)
- **Fail**: Any compilation errors
- **Check**: Did ALL relevant files build, or just some?

### ‚òê 2. Proof Verification
For each theorem claimed as "proven":
```bash
# Check theorem body
grep -A 5 "theorem <name>" <file>.lean
```
- **Real proof**: Has actual proof steps (not `trivial`, not `sorry`)
- **Trivial placeholder**: `True := by trivial` (NOT A REAL PROOF)
- **Sorry**: `sorry` (UNPROVEN)
- **Check**: Are theorems proving the actual statements or just `True`?

### ‚òê 3. Import Verification
```bash
# Check if file is imported in root
grep -r "import.*<YourFile>" lean/LogicRealismTheory.lean
```
- **Imported**: File is part of build (real)
- **Not imported**: File exists but orphaned (wasted effort)
- **Check**: Is the work actually integrated?

### ‚òê 4. Axiom Count Reality
```bash
# Count axioms in file
grep -c "^axiom " lean/LogicRealismTheory/<Module>/<File>.lean
```
- **Document**: How many axioms added vs removed?
- **Classify**: K_math, LRT_foundational, Measurement_dynamics, etc.
- **Check**: Did axiom count go UP when claiming to "prove" things?

### ‚òê 5. Deliverable Reality Check
For each claimed deliverable:
- **Documentation only**: Markdown file explaining theory (informal argument)
- **Lean structure**: Type signatures, axioms, imports (scaffolding)
- **Lean proof**: Theorem with non-trivial proof body (actual verification)
- **Check**: Which category does each deliverable actually fall into?

### ‚òê 6. Professional Tone Verification
Review all documentation and commit messages for professionalism:
- **No celebration language**: Avoid üéâ, "amazing", "breakthrough", "historic" before peer review
- **No emojis**: Unless explicitly requested by user
- **No superlatives**: "significant", "important", "notable" instead of "groundbreaking", "revolutionary"
- **Measured claims**: "This appears to..." not "This proves..."
- **Honest assessment**: Lead with limitations, not achievements
- **Check**: Would a peer reviewer find this tone appropriate for academic work?

**Red flags**:
- ‚ùå Excessive enthusiasm (üéâ COMPLETE! AMAZING! BREAKTHROUGH!)
- ‚ùå Premature celebration (claiming success before verification)
- ‚ùå Marketing language ("revolutionary", "paradigm shift", "game-changing")
- ‚ùå Overconfident claims ("definitively proves", "conclusively shows")

**Acceptable tone**:
- ‚úÖ Technical and measured ("results suggest", "appears consistent with")
- ‚úÖ Explicit about limitations ("pending verification", "preliminary results")
- ‚úÖ Professional restraint (state facts, not excitement)
- ‚úÖ Academic standard (like arxiv preprints, not press releases)

---

## Stop Words

Do NOT use these words without passing sanity check:

‚ùå **"Verified"** - unless theorems have real proofs (not `trivial`, not `sorry`)
‚ùå **"Proven"** - unless theorem body proves actual statement (not `True`)
‚ùå **"Complete"** - unless all proof obligations satisfied
‚ùå **"Formalized"** - unless file imported and builds
‚ùå **"Derived"** - unless derivation is formal proof (not informal argument)

‚úÖ **Acceptable alternatives**:
- "Documented" (for markdown files)
- "Structured" (for type signatures/axioms)
- "Builds successfully" (for compilation)
- "Informal argument provided" (for theory explanations)
- "Axiom structure in place" (for scaffolding)

---

## Reality Check Questions

Ask these before claiming completion:

1. **If a skeptical peer reviewer read this, would they agree it's "complete"?**
2. **Did I write proofs or did I write documentation about proofs?**
3. **Can I point to specific theorem bodies with non-trivial proof steps?**
4. **Did the axiom count go DOWN (real reduction) or UP (more assumptions)?**
5. **Is this actual object-level work or meta-level process work?**

---

## Specific File Checks

### For Lean Files

**Pass Criteria**:
- ‚úÖ File imported in `LogicRealismTheory.lean`
- ‚úÖ `lake build` succeeds with 0 errors
- ‚úÖ Theorems prove actual statements (not `True`)
- ‚úÖ No unresolved `sorry` statements (or explicitly documented as K_math/axioms)
- ‚úÖ Axiom count change documented in tracking

**Fail Indicators**:
- ‚ùå File not imported (orphaned)
- ‚ùå Theorems prove `True` with `trivial`
- ‚ùå Theorems end with `sorry`
- ‚ùå Axiom count increased when claiming "proven"
- ‚ùå Build errors or warnings about unused variables

### For Markdown Documentation

**Pass Criteria**:
- ‚úÖ Clearly labeled as "informal argument" or "conceptual derivation"
- ‚úÖ Does NOT claim "formally verified" or "proven in Lean"
- ‚úÖ References Lean files accurately (doesn't overstate their contents)
- ‚úÖ Honest about what's derived vs what's assumed

**Fail Indicators**:
- ‚ùå Claims "verified" when only documented
- ‚ùå Claims "complete" when Lean has `sorry`/`True`
- ‚ùå Implies formal verification without checking theorem bodies
- ‚ùå Counts markdown lines as "formalization"

### For Sprint Tracks

**Pass Criteria**:
- ‚úÖ All deliverables pass their respective checks above
- ‚úÖ Tracking document accurately reflects pass/fail status
- ‚úÖ No conflation of "documentation complete" with "proofs complete"
- ‚úÖ Honest percentage: what % is formal proof vs informal argument?

**Fail Indicators**:
- ‚ùå "100% complete" when theorems have `sorry`
- ‚ùå "Fully formalized" when proofs are `trivial`
- ‚ùå Celebration (üéâ) before verification
- ‚ùå Counts files created, not theorems proven

---

## Output Format

After running sanity check, report:

```markdown
## Sanity Check Results - [Track Name]

**Build Status**: ‚úÖ/‚ùå [0 errors] / [N errors]
**Files Imported**: ‚úÖ/‚ùå [N/N files] / [N/M files - M orphaned]
**Proof Status**:
  - Real proofs: N theorems
  - Trivial placeholders: N theorems (proving `True`)
  - Unproven: N theorems (`sorry`)
**Axiom Count**: Start: X, End: Y, Change: +/-Z
**Deliverable Reality**:
  - Documentation: N files
  - Lean structure: N files
  - Lean proofs: N theorems with real proof bodies
**Professional Tone**: ‚úÖ/‚ùå [Measured and appropriate] / [Excessive enthusiasm detected]

**Honest Assessment**: [1-2 sentence summary of what was actually achieved]

**Proceed?**: ‚úÖ YES / ‚ùå NO - [reason]
```

---

## When to Escalate to User

Invoke this check yourself first. If you get:
- ‚ùå on ANY of the 5 quick checks
- Discrepancy between claimed and actual completion
- Uncertainty about proof vs placeholder
- Temptation to use stop words without verification

Then STOP and report results to user BEFORE claiming completion.

---

## Protocol Status

**Version**: 1.0
**Created**: 2025-11-04
**Purpose**: Mitigation for AI-assistant overclaiming patterns (Session 8 lessons)
**Usage**: Mandatory after each track, optional during track for mid-point check

---

**This protocol exists because**: Session 8 discovered systematic overclaiming of "BUILD SUCCESS" as "formal verification". This check distinguishes compilation from proof completion.
