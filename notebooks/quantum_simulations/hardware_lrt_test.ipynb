{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hardware Test: Logical State-Dependent Error (LRT Prediction)\n",
    "\n",
    "## Real IBM Quantum Hardware Validation\n",
    "\n",
    "**Copyright © 2025 James D. (JD) Longmire**  \n",
    "**License**: Apache License 2.0  \n",
    "**Citation**: Longmire, J.D. (2025). *Logic Realism Theory: A Research Program for Ontological Logic in Informational Reality*. Logic Realism Theory Repository.\n",
    "\n",
    "---\n",
    "\n",
    "## Purpose\n",
    "\n",
    "This notebook runs the **first real hardware test** of Logic Realism Theory predictions.\n",
    "\n",
    "**Test**: Logical State-Dependent Error  \n",
    "**Prediction**: Superposition states |+⟩ may have excess error beyond standard T2 decoherence  \n",
    "**Method**: Ramsey experiment on IBM ibm_torino (133-qubit processor)  \n",
    "**Budget**: 25 points × 2,500 shots = 62,500 shots (~5-7 minutes of quantum time)\n",
    "\n",
    "---\n",
    "\n",
    "## Test Design\n",
    "\n",
    "**Parent Document**: `theory/predictions/Logical_State_Dependent_Error_Test_Design.md`  \n",
    "**Phase 3 Validation**: `theory/predictions/Phase_3_Results_Report.md` (VIF = 1.0, MDE = 0.5%)\n",
    "\n",
    "**Status**: Hardware-ready (multi-LLM approved, quality 0.69, Phase 3 complete)\n",
    "\n",
    "---\n",
    "\n",
    "## ⚠️ IMPORTANT: This Will Use Real Quantum Time\n",
    "\n",
    "- Estimated runtime: **5-7 minutes** of ibm_torino processor time\n",
    "- Queue wait: **Variable** (413 pending jobs as of 2025-10-26)\n",
    "- Budget remaining after: ~3-5 minutes for retries/analysis\n",
    "\n",
    "**Confirmation required before submission (see Step 5)**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import linregress\n",
    "from scipy.optimize import curve_fit\n",
    "import time\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# Qiskit\n",
    "from qiskit import QuantumCircuit, transpile\n",
    "from qiskit_ibm_runtime import QiskitRuntimeService, Session, SamplerV2 as Sampler\n",
    "\n",
    "print(\"Environment setup complete\")\n",
    "print(f\"Current time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Connect to IBM Quantum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load API token\n",
    "with open('../../theory/predictions/IBM_Q_API.txt', 'r') as f:\n",
    "    token = f.read().strip()\n",
    "\n",
    "# Connect to IBM Quantum\n",
    "print(\"Connecting to IBM Quantum Platform...\")\n",
    "try:\n",
    "    service = QiskitRuntimeService(channel=\"ibm_quantum_platform\", token=token)\n",
    "    print(\"Connected successfully (token loaded)\")\n",
    "except:\n",
    "    # If already saved\n",
    "    service = QiskitRuntimeService(channel=\"ibm_quantum_platform\")\n",
    "    print(\"Connected successfully (saved credentials)\")\n",
    "\n",
    "# Get backend\n",
    "backend = service.backend('ibm_torino')\n",
    "print(f\"\\nBackend: {backend.name}\")\n",
    "print(f\"Status: {backend.status().status_msg}\")\n",
    "print(f\"Queue: {backend.status().pending_jobs} pending jobs\")\n",
    "print(f\"Qubits: {backend.configuration().n_qubits}\")\n",
    "print(f\"Max shots: {backend.configuration().max_shots:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Test Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hardware test parameters (reduced for 10-minute budget)\n",
    "N_SHOTS = 2500  # Shots per circuit (vs Phase 3: 10,000)\n",
    "N_POINTS = 25   # Duration points (vs Phase 3: 49)\n",
    "\n",
    "# Duration sweep (will be calibrated to measured T2)\n",
    "# Start with typical IBM range: T2 ~ 60-150 us\n",
    "T2_ESTIMATE = 100e-6  # 100 us (conservative estimate)\n",
    "\n",
    "# Log + Linear sampling (optimized from Phase 3)\n",
    "T_MIN = 1e-6  # 1 us\n",
    "T_MAX = 5 * T2_ESTIMATE  # 500 us (5*T2)\n",
    "\n",
    "# Generate duration points\n",
    "T_log = np.logspace(np.log10(T_MIN), np.log10(T2_ESTIMATE), 13)  # 1 us to T2\n",
    "T_lin = np.linspace(T2_ESTIMATE, T_MAX, 13)  # T2 to 5*T2\n",
    "T_sweep = np.sort(np.concatenate([T_log, T_lin[1:]]))  # 25 points total\n",
    "\n",
    "print(\"Hardware Test Parameters:\")\n",
    "print(f\"  Shots per circuit: {N_SHOTS:,}\")\n",
    "print(f\"  Duration points: {N_POINTS}\")\n",
    "print(f\"  Total shots: {N_SHOTS * N_POINTS:,}\")\n",
    "print(f\"  Duration range: {T_sweep.min()*1e6:.2f} to {T_sweep.max()*1e6:.1f} us\")\n",
    "print(f\"  Estimated T2: {T2_ESTIMATE*1e6:.0f} us\")\n",
    "print(f\"\\nEstimated quantum time: ~5-7 minutes\")\n",
    "print(f\"Budget remaining after: ~3-5 minutes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Build Ramsey Circuits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_ramsey_circuit(duration_sec, qubit=0):\n",
    "    \"\"\"\n",
    "    Build Ramsey experiment circuit.\n",
    "    \n",
    "    Circuit: H - delay(T) - H - Measure\n",
    "    Prepares |+⟩, waits duration T, measures in X-basis.\n",
    "    \n",
    "    Args:\n",
    "        duration_sec: Wait time in seconds\n",
    "        qubit: Which qubit to use (default 0)\n",
    "    \n",
    "    Returns:\n",
    "        QuantumCircuit\n",
    "    \"\"\"\n",
    "    qc = QuantumCircuit(1, 1)\n",
    "    \n",
    "    # Prepare |+⟩ (superposition state)\n",
    "    qc.h(0)\n",
    "    \n",
    "    # Wait (decoherence happens here)\n",
    "    qc.delay(duration_sec, 0, unit='s')\n",
    "    \n",
    "    # Measure in X-basis (rotate back with H)\n",
    "    qc.h(0)\n",
    "    qc.measure(0, 0)\n",
    "    \n",
    "    return qc\n",
    "\n",
    "# Build all circuits\n",
    "print(\"Building Ramsey circuits...\")\n",
    "circuits = []\n",
    "for T in T_sweep:\n",
    "    qc = build_ramsey_circuit(T, qubit=0)\n",
    "    circuits.append(qc)\n",
    "\n",
    "print(f\"Built {len(circuits)} circuits\")\n",
    "\n",
    "# Show example circuit (shortest duration)\n",
    "print(\"\\nExample circuit (T = 1 us):\")\n",
    "print(circuits[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Transpile for Hardware"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transpile circuits for ibm_torino\n",
    "print(\"Transpiling circuits for ibm_torino...\")\n",
    "print(\"This may take 1-2 minutes...\")\n",
    "\n",
    "start_time = time.time()\n",
    "transpiled_circuits = transpile(\n",
    "    circuits,\n",
    "    backend=backend,\n",
    "    optimization_level=3,  # Maximum optimization\n",
    "    initial_layout=[0],     # Use qubit 0\n",
    ")\n",
    "elapsed = time.time() - start_time\n",
    "\n",
    "print(f\"Transpilation complete ({elapsed:.1f}s)\")\n",
    "print(f\"Total transpiled circuits: {len(transpiled_circuits)}\")\n",
    "\n",
    "# Show gate counts\n",
    "example = transpiled_circuits[0]\n",
    "print(f\"\\nExample transpiled circuit (T = 1 us):\")\n",
    "print(f\"  Depth: {example.depth()}\")\n",
    "print(f\"  Gate count: {example.count_ops()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: ⚠️ SUBMIT TO HARDWARE (Confirmation Required)\n",
    "\n",
    "**This will use ~5-7 minutes of quantum time.**\n",
    "\n",
    "**Before running this cell, confirm:**\n",
    "- ✅ You understand this uses real quantum time\n",
    "- ✅ Queue is acceptable (check status above)\n",
    "- ✅ You're ready to wait for results\n",
    "\n",
    "**To proceed: Change `CONFIRMED = False` to `CONFIRMED = True` below, then run.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Safety: Require explicit confirmation\n",
    "CONFIRMED = False  # Change to True to proceed\n",
    "\n",
    "if not CONFIRMED:\n",
    "    print(\"⚠️ SUBMISSION NOT CONFIRMED\")\n",
    "    print(\"To submit to hardware, change CONFIRMED = True above and re-run this cell.\")\n",
    "    print(\"\\nThis will:\")\n",
    "    print(f\"  - Submit {len(transpiled_circuits)} circuits to ibm_torino\")\n",
    "    print(f\"  - Run {N_SHOTS:,} shots per circuit\")\n",
    "    print(f\"  - Use ~5-7 minutes of quantum time\")\n",
    "    print(f\"  - Current queue: {backend.status().pending_jobs} jobs\")\n",
    "else:\n",
    "    print(\"✅ CONFIRMED - Submitting to hardware...\")\n",
    "    print(f\"Current time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "    print(f\"Queue status: {backend.status().pending_jobs} pending jobs\")\n",
    "    print(\"\\nOpening session...\")\n",
    "    \n",
    "    # Open session and submit\n",
    "    with Session(backend=backend) as session:\n",
    "        sampler = Sampler(session=session)\n",
    "        \n",
    "        print(\"Submitting job...\")\n",
    "        job = sampler.run(\n",
    "            transpiled_circuits,\n",
    "            shots=N_SHOTS\n",
    "        )\n",
    "        \n",
    "        job_id = job.job_id()\n",
    "        print(f\"\\n✅ Job submitted successfully!\")\n",
    "        print(f\"Job ID: {job_id}\")\n",
    "        print(f\"Status: {job.status()}\")\n",
    "        \n",
    "        # Save job ID for recovery\n",
    "        with open('hardware_test_job_id.txt', 'w') as f:\n",
    "            f.write(job_id)\n",
    "        print(f\"\\nJob ID saved to: hardware_test_job_id.txt\")\n",
    "        \n",
    "        # Monitor job\n",
    "        print(\"\\nWaiting for results (this may take time depending on queue)...\")\n",
    "        print(\"You can close this notebook and retrieve results later using the Job ID.\")\n",
    "        print(\"\\nMonitoring job status...\")\n",
    "        \n",
    "        while job.status() not in ['DONE', 'CANCELLED', 'ERROR']:\n",
    "            status = job.status()\n",
    "            print(f\"  Status: {status} - {datetime.now().strftime('%H:%M:%S')}\")\n",
    "            time.sleep(30)  # Check every 30 seconds\n",
    "        \n",
    "        final_status = job.status()\n",
    "        print(f\"\\n✅ Job completed: {final_status}\")\n",
    "        print(f\"Completion time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "        \n",
    "        if final_status == 'DONE':\n",
    "            # Retrieve results\n",
    "            print(\"\\nRetrieving results...\")\n",
    "            result = job.result()\n",
    "            \n",
    "            # Save raw results\n",
    "            print(\"Saving raw results...\")\n",
    "            with open('hardware_test_results.json', 'w') as f:\n",
    "                json.dump({\n",
    "                    'job_id': job_id,\n",
    "                    'backend': backend.name,\n",
    "                    'n_shots': N_SHOTS,\n",
    "                    'n_points': N_POINTS,\n",
    "                    'T_sweep': T_sweep.tolist(),\n",
    "                    'timestamp': datetime.now().isoformat(),\n",
    "                    'status': str(final_status)\n",
    "                }, f, indent=2)\n",
    "            \n",
    "            print(\"\\n✅ Results saved successfully!\")\n",
    "            print(\"Files created:\")\n",
    "            print(\"  - hardware_test_job_id.txt\")\n",
    "            print(\"  - hardware_test_results.json\")\n",
    "            print(\"\\nProceed to Step 7 to analyze results.\")\n",
    "        else:\n",
    "            print(f\"\\n❌ Job failed with status: {final_status}\")\n",
    "            print(\"Check IBM Quantum dashboard for details.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Process Hardware Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load results (either from previous cell or from saved file)\n",
    "print(\"Processing hardware results...\")\n",
    "\n",
    "if 'result' not in locals():\n",
    "    print(\"Loading results from file...\")\n",
    "    # Reconnect and retrieve job\n",
    "    with open('hardware_test_job_id.txt', 'r') as f:\n",
    "        job_id = f.read().strip()\n",
    "    \n",
    "    job = service.job(job_id)\n",
    "    result = job.result()\n",
    "    print(f\"Results loaded for job: {job_id}\")\n",
    "\n",
    "# Extract measurement counts\n",
    "results_data = []\n",
    "for i, T in enumerate(T_sweep):\n",
    "    # Get counts for this circuit\n",
    "    counts = result[i].data.c.get_counts()\n",
    "    \n",
    "    # Calculate probabilities\n",
    "    counts_0 = counts.get(0, 0)  # |0⟩ (logical |+⟩)\n",
    "    counts_1 = counts.get(1, 0)  # |1⟩ (logical |-⟩, error)\n",
    "    total = counts_0 + counts_1\n",
    "    \n",
    "    p_error = counts_1 / total if total > 0 else 0\n",
    "    \n",
    "    results_data.append({\n",
    "        'T': T,\n",
    "        'T_us': T * 1e6,\n",
    "        'counts_0': counts_0,\n",
    "        'counts_1': counts_1,\n",
    "        'p_error': p_error,\n",
    "        'shots': total\n",
    "    })\n",
    "\n",
    "df_hardware = pd.DataFrame(results_data)\n",
    "print(f\"\\nProcessed {len(df_hardware)} data points\")\n",
    "print(f\"Total shots collected: {df_hardware['shots'].sum():,}\")\n",
    "print(\"\\nFirst 5 data points:\")\n",
    "print(df_hardware[['T_us', 'p_error', 'shots']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: T2 Characterization from Hardware Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ramsey_model(T, A, T2):\n",
    "    \"\"\"Ramsey decay: p_error(T) = A * (1 - exp(-T/T2))\"\"\"\n",
    "    return A * (1 - np.exp(-T / T2))\n",
    "\n",
    "# Fit T2 from hardware data\n",
    "print(\"Fitting T2 from hardware measurements...\")\n",
    "\n",
    "try:\n",
    "    popt, pcov = curve_fit(\n",
    "        ramsey_model,\n",
    "        df_hardware['T'],\n",
    "        df_hardware['p_error'],\n",
    "        p0=[0.5, T2_ESTIMATE],\n",
    "        bounds=([0, 1e-6], [1, 1e-3]),  # Reasonable bounds\n",
    "        maxfev=10000\n",
    "    )\n",
    "    \n",
    "    A_fit, T2_fit = popt\n",
    "    \n",
    "    print(f\"\\n✅ T2 Characterization Results:\")\n",
    "    print(f\"  Fitted T2: {T2_fit*1e6:.2f} us\")\n",
    "    print(f\"  Fitted amplitude: {A_fit:.4f}\")\n",
    "    print(f\"  Expected amplitude: ~0.5\")\n",
    "    \n",
    "    # Generate QM baseline prediction\n",
    "    df_hardware['p_predicted'] = ramsey_model(df_hardware['T'], A_fit, T2_fit)\n",
    "    df_hardware['residual'] = df_hardware['p_error'] - df_hardware['p_predicted']\n",
    "    \n",
    "    # Calculate R²\n",
    "    ss_res = np.sum(df_hardware['residual']**2)\n",
    "    ss_tot = np.sum((df_hardware['p_error'] - df_hardware['p_error'].mean())**2)\n",
    "    R2 = 1 - (ss_res / ss_tot)\n",
    "    \n",
    "    print(f\"  R²: {R2:.4f} (QM fit quality)\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\n❌ Fit failed: {e}\")\n",
    "    print(\"Using estimated T2 for baseline.\")\n",
    "    T2_fit = T2_ESTIMATE\n",
    "    A_fit = 0.5\n",
    "    df_hardware['p_predicted'] = ramsey_model(df_hardware['T'], A_fit, T2_fit)\n",
    "    df_hardware['residual'] = df_hardware['p_error'] - df_hardware['p_predicted']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Residual Analysis - LRT Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"LRT TEST: Residual Analysis\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Regression: Δp(T) = β_LRT * T + ε\n",
    "slope, intercept, r_value, p_value, std_err = linregress(\n",
    "    df_hardware['T'],\n",
    "    df_hardware['residual']\n",
    ")\n",
    "\n",
    "print(f\"\\nRegression Results:\")\n",
    "print(f\"  β_LRT (slope): {slope:.6e} ± {std_err:.6e}\")\n",
    "print(f\"  Intercept:     {intercept:.6e}\")\n",
    "print(f\"  R²:            {r_value**2:.4f}\")\n",
    "print(f\"  p-value:       {p_value:.4f}\")\n",
    "\n",
    "print(f\"\\n\" + \"=\" * 70)\n",
    "if p_value < 0.05:\n",
    "    excess_pct = slope * T2_fit * 100  # Excess error at T = T2\n",
    "    print(\"🔴 LRT SIGNAL DETECTED\")\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"\\nStatistically significant excess error detected!\")\n",
    "    print(f\"  Excess error at T=T2: {excess_pct:.2f}%\")\n",
    "    print(f\"  Confidence: p = {p_value:.4f} < 0.05\")\n",
    "    print(f\"\\nThis supports LRT prediction that superposition states\")\n",
    "    print(f\"have excess error beyond standard QM decoherence.\")\n",
    "else:\n",
    "    print(\"🟢 NO LRT SIGNAL DETECTED\")\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"\\nNo statistically significant excess error.\")\n",
    "    print(f\"  p-value: {p_value:.4f} > 0.05\")\n",
    "    print(f\"  β_LRT: {slope:.6e} (consistent with 0)\")\n",
    "    print(f\"\\nResult is consistent with standard QM.\")\n",
    "    print(f\"LRT prediction not supported by this data.\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "\n",
    "# Statistical summary\n",
    "print(f\"\\nResidual Statistics:\")\n",
    "print(f\"  Mean:   {df_hardware['residual'].mean():.6e}\")\n",
    "print(f\"  Std:    {df_hardware['residual'].std():.6e}\")\n",
    "print(f\"  Min:    {df_hardware['residual'].min():.6e}\")\n",
    "print(f\"  Max:    {df_hardware['residual'].max():.6e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10: Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive visualization\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 10))\n",
    "\n",
    "# Panel A: T2 Characterization\n",
    "ax1.scatter(df_hardware['T_us'], df_hardware['p_error'], \n",
    "            alpha=0.6, s=50, label=f'Hardware Data (N={N_SHOTS} shots)')\n",
    "\n",
    "T_fine = np.linspace(df_hardware['T'].min(), df_hardware['T'].max(), 200)\n",
    "p_fine = ramsey_model(T_fine, A_fit, T2_fit)\n",
    "ax1.plot(T_fine * 1e6, p_fine, 'r-', linewidth=2, \n",
    "         label=f'QM Fit (T2={T2_fit*1e6:.1f} us, R²={R2:.4f})')\n",
    "\n",
    "ax1.set_xlabel('Duration T (us)', fontsize=12)\n",
    "ax1.set_ylabel('Error Probability p(|-⟩)', fontsize=12)\n",
    "ax1.set_title('Panel A: T2 Characterization via Ramsey Experiment', \n",
    "              fontsize=14, fontweight='bold')\n",
    "ax1.legend(loc='lower right', fontsize=10)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Panel B: Residual Analysis (LRT Test)\n",
    "ax2.scatter(df_hardware['T_us'], df_hardware['residual'], \n",
    "            alpha=0.6, s=50, color='blue', label='Residuals')\n",
    "\n",
    "# Regression line\n",
    "T_fit = np.array([df_hardware['T'].min(), df_hardware['T'].max()])\n",
    "residual_fit = slope * T_fit + intercept\n",
    "ax2.plot(T_fit * 1e6, residual_fit, 'r--', linewidth=2, \n",
    "         label=f'Linear Fit: β={slope:.2e}, p={p_value:.4f}')\n",
    "\n",
    "ax2.axhline(0, color='k', linestyle=':', alpha=0.5)\n",
    "\n",
    "ax2.set_xlabel('Duration T (us)', fontsize=12)\n",
    "ax2.set_ylabel('Residual Δp = p_observed - p_QM', fontsize=12)\n",
    "\n",
    "if p_value < 0.05:\n",
    "    ax2.set_title('Panel B: LRT Test - SIGNAL DETECTED', \n",
    "                  fontsize=14, fontweight='bold', color='red')\n",
    "else:\n",
    "    ax2.set_title('Panel B: LRT Test - No Signal (QM Consistent)', \n",
    "                  fontsize=14, fontweight='bold', color='green')\n",
    "\n",
    "ax2.legend(loc='best', fontsize=10)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('hardware_lrt_test_results.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n✅ Figure saved: hardware_lrt_test_results.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 11: Save Final Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save comprehensive results report\n",
    "report = {\n",
    "    'metadata': {\n",
    "        'backend': backend.name,\n",
    "        'job_id': job_id if 'job_id' in locals() else 'N/A',\n",
    "        'timestamp': datetime.now().isoformat(),\n",
    "        'n_shots': N_SHOTS,\n",
    "        'n_points': N_POINTS,\n",
    "        'total_shots': N_SHOTS * N_POINTS\n",
    "    },\n",
    "    'T2_characterization': {\n",
    "        'T2_fitted_us': float(T2_fit * 1e6),\n",
    "        'amplitude': float(A_fit),\n",
    "        'R2': float(R2) if 'R2' in locals() else None\n",
    "    },\n",
    "    'LRT_test': {\n",
    "        'beta_LRT': float(slope),\n",
    "        'beta_LRT_stderr': float(std_err),\n",
    "        'intercept': float(intercept),\n",
    "        'R2': float(r_value**2),\n",
    "        'p_value': float(p_value),\n",
    "        'signal_detected': p_value < 0.05,\n",
    "        'excess_error_pct_at_T2': float(slope * T2_fit * 100) if p_value < 0.05 else 0\n",
    "    },\n",
    "    'residual_stats': {\n",
    "        'mean': float(df_hardware['residual'].mean()),\n",
    "        'std': float(df_hardware['residual'].std()),\n",
    "        'min': float(df_hardware['residual'].min()),\n",
    "        'max': float(df_hardware['residual'].max())\n",
    "    },\n",
    "    'data': df_hardware.to_dict('records')\n",
    "}\n",
    "\n",
    "with open('hardware_lrt_test_report.json', 'w') as f:\n",
    "    json.dump(report, f, indent=2)\n",
    "\n",
    "print(\"✅ Results saved to: hardware_lrt_test_report.json\")\n",
    "print(\"\\nFinal Summary:\")\n",
    "print(f\"  Backend: {backend.name}\")\n",
    "print(f\"  Total shots: {N_SHOTS * N_POINTS:,}\")\n",
    "print(f\"  T2 (fitted): {T2_fit*1e6:.2f} us\")\n",
    "print(f\"  β_LRT: {slope:.2e} ± {std_err:.2e}\")\n",
    "print(f\"  p-value: {p_value:.4f}\")\n",
    "print(f\"  LRT signal: {'YES' if p_value < 0.05 else 'NO'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "This notebook implements the first real hardware test of Logic Realism Theory predictions.\n",
    "\n",
    "**Test Design Validated**: Multi-LLM approved (quality 0.69), Phase 3 simulation validated (VIF = 1.0, MDE = 0.5%)\n",
    "\n",
    "**Hardware Test**: IBM ibm_torino (133-qubit processor)\n",
    "\n",
    "**Analysis**: Residual analysis framework isolates LRT effect from standard QM baseline\n",
    "\n",
    "**Next Steps**:\n",
    "- Review results in `hardware_lrt_test_report.json`\n",
    "- Check visualization in `hardware_lrt_test_results.png`\n",
    "- Document findings in session log\n",
    "- If LRT signal detected: Write up results for paper\n",
    "- If no signal: Document upper bounds, consider alternative tests\n",
    "\n",
    "---\n",
    "\n",
    "**Files Created**:\n",
    "- `hardware_test_job_id.txt` - Job ID for recovery\n",
    "- `hardware_test_results.json` - Raw measurement data\n",
    "- `hardware_lrt_test_report.json` - Comprehensive analysis\n",
    "- `hardware_lrt_test_results.png` - Visualization\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
